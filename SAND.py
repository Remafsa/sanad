import os
import json
from pathlib import Path
import datetime
import streamlit as st
from dotenv import load_dotenv, find_dotenv
from langchain_core.documents import Document
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
import fitz  # PyMuPDF
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain, LLMChain
from langchain import PromptTemplate
from langchain.llms import OpenAI as LangChainOpenAI  # Correct import for OpenAI LLM

# Set the page config at the top of the script
st.set_page_config(layout="wide", page_title="Ø³Ù€Ù†Ø¯", page_icon="âš–ï¸")

load_dotenv()

# Get the OpenAI API key from the environment variables
openai_api_key = os.getenv('OPENAI_API_KEY')
embedding = OpenAIEmbeddings()

# Custom CSS to move sidebar to the right
st.markdown("""
        <style>
        body {
            direction: rtl;
            text-align: right;
        }
        .stTextInput label {
            float: right;
        }
        </style>
        """, unsafe_allow_html=True)

# Streamlit app setup
with st.sidebar:
    st.image("/Users/remaalnssiry/Desktop/SAND/Logo.png", width=150)
    app_selection = st.sidebar.radio("Ø£Ø®ØªØ±:", ["Ø§Ù„Ø¨Ø§Ø­Ø« Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ", "Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©"])

def app1():
    # Add custom CSS for chat messages
    st.markdown("""
    <style>
    # .stTextInput, .stMarkdown, .stButton {
    # float: right;
    # }
    .title {
        text-align: center;
        font-size: 2.5em;
        color: ##e0f7fa;
    }
    .chat-message-user, .chat-message-ai {
        display: flex;
        align-items: center;
        border-radius: 10px;
        padding: 10px;
        margin-bottom: 10px;
        max-width: 80%;
    }
    .chat-message-user {
        background-color: #e0f7fa;
        align-self: flex-end;
        justify-content: flex-end;
        color: #004d40;
        float: right;
    }
    .chat-message-user::before {
        content: "ğŸ‘¤"; /* Custom icon for user */
        margin-left: 10px;
    }
    .chat-message-ai {
        background-color: #e8f5e9;
        align-self: flex-start;
        justify-content: flex-start;
        color: #2e7d32;
        float: left;
    }
    .chat-message-ai::before {
        content: "ğŸ¤–"; /* Custom icon for AI */
        margin-right: 10px;

    }
    .chat-container {
        display: flex;
        flex-direction: column;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown('<h1 class="title"> âš–ï¸ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©</h1>', unsafe_allow_html=True)

    # Load documents
    directory = Path("/Users/remaalnssiry/Desktop/SAND/Legal_researcher/best_chatboot")
    documents = []
    for file_path in directory.glob('*.json'):
        with open(file_path, "r", encoding="utf-8") as json_file:
            data = json.load(json_file)
            metadata = {
                'Ø§Ù„Ø±Ø§Ø¨Ø·': data['Ø§Ù„Ø±Ø§Ø¨Ø·'],
                'Ø§Ù„Ù…Ù„Ù': str(file_path),
                'Ø§Ù„Ù†Ø¸Ø§Ù…': data['Ø§Ù„Ù†Ø¸Ø§Ù…'],
            }
            for chapter, articles in data['Ø§Ù„ÙØµÙˆÙ„'].items():
                for article, content in articles.items():
                    documents.append(Document(content, metadata={**metadata, 'Ø§Ù„ÙØµÙ„': chapter, 'Ø§Ù„Ù…Ø§Ø¯Ø©': article}))

    # Initialize embedding and retriever
    embedding = OpenAIEmbeddings()
    retriever = Chroma(
        persist_directory="/Users/remaalnssiry/Desktop/SAND/Legal_researcher/docs2_best/chroma",
        embedding_function=embedding
    ).as_retriever()

    # Split documents
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1737,
        chunk_overlap=150,
        length_function=len
    )
    splits = text_splitter.split_documents(documents)

    # Set model based on date
    current_date = datetime.datetime.now().date()
    llm_name = "gpt-3.5-turbo-0301" if current_date < datetime.date(2023, 9, 2) else "gpt-3.5-turbo"
    llm = ChatOpenAI(model_name=llm_name, temperature=0)

    # Set up QA chain with prompt
    template = """Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©. Ø¥Ø°Ø§ ÙƒÙ†Øª Ù„Ø§ ØªØ¹Ø±Ù Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ù‚Ù„ ÙÙ‚Ø· Ø£Ù†Ùƒ Ù„Ø§ ØªØ¹Ø±ÙØŒ ÙˆÙ„Ø§ ØªØ­Ø§ÙˆÙ„ Ø§Ø®ØªÙ„Ø§Ù‚ Ø¥Ø¬Ø§Ø¨Ø©. Ø§Ø³ØªØ®Ø¯Ù… Ø«Ù„Ø§Ø« Ø¬Ù…Ù„ ÙƒØ­Ø¯ Ø§Ù‚Ù„. Ù‚Ù„ Ø¯Ø§Ø¦Ù…Ù‹Ø§ "Ø´ÙƒØ±Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„!" ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬ÙˆØ§Ø¨.
    {context}
    Question: {question}
    Helpful Answer:"""
    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
    )

    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display chat history
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            st.markdown(f'<div class="chat-message-user">{msg["content"]}</div>', unsafe_allow_html=True)
        else:
            st.markdown(f'<div class="chat-message-ai">{msg["content"]}</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

    # Input field for user to type a message
    user_input = st.text_input("", key="user_input")
    if st.button("Ø§Ø±Ø³Ù„"):
        if user_input:
            st.session_state.messages.append({"role": "user", "content": user_input})

            # Retrieve relevant documents and generate response
            docs_ = retriever.get_relevant_documents(user_input)
            result = qa_chain({"query": user_input})
            answer = result["result"]
            st.session_state.messages.append({"role": "assistant", "content": answer})

            st.experimental_rerun()  # Rerun the app to display the new message

def app2():
    dataset_dir = "/Users/remaalnssiry/Desktop/SAND/dataset"

    llm = ChatOpenAI(temperature=0)
    map_template = """ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠÙ‡ ØªØªØ¹Ù„Ù‚ Ø¨Ø­Ø§Ù„Ø§Øª Ø­Ø¯Ø«Øª ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠÙ‡ ÙˆØ§Ù„Ø­ÙƒÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„ØªÙŠ Ø­Ø¯Ø«Øª ÙÙŠÙ‡Ø§ØŒ
    ØªÙ… Ø·Ù…Ø³ Ø§Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø´Ø®Ø§Øµ ÙˆØ¨Ø¹Ø¶ Ø§Ù„Ø§Ù…Ø§ÙƒÙ† Ø§Ù„ØªÙŠ ØªØ®Øµ ÙƒÙ„ Ù‚Ø¶ÙŠØ© ÙˆØ§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ø¨Ù€ `(...)` Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¬Ù…ÙŠØ¹:
    '''
    {docs}
    '''
    Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù‡Ø°Ù‡ØŒ ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ ÙƒÙ„ Ø­Ø§Ù„Ø©.
    """
    map_prompt = PromptTemplate.from_template(map_template)
    map_chain = LLMChain(llm=llm, prompt=map_prompt)

    reduce_template = """ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ø®ØµØ§Øª Ù„Ø­Ø§Ù„Ø§Øª ØªØ´Ù…Ù„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ®:
    {docs}
    ÙŠØ±Ø¬Ù‰ Ø£Ø®Ø° Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„Ø®ØµØ§Øª ÙˆØ§Ø®ØªØµØ§Ø±Ù‡Ø§ ÙÙŠ Ù…Ù„Ø®Øµ Ù†Ù‡Ø§Ø¦ÙŠ ÙˆÙ…ÙˆØ­Ø¯ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.
    """
    reduce_prompt = PromptTemplate.from_template(reduce_template)
    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)

    combine_documents_chain = StuffDocumentsChain(llm_chain=reduce_chain, document_variable_name="docs")
    reduce_documents_chain = ReduceDocumentsChain(combine_documents_chain=combine_documents_chain, collapse_documents_chain=combine_documents_chain, token_max=4000)
    map_reduce_chain = MapReduceDocumentsChain(llm_chain=map_chain, reduce_documents_chain=reduce_documents_chain, document_variable_name="docs", return_intermediate_steps=False)

    summarized_docs = []
    pdf_summaries = {}

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    retriever = Chroma(persist_directory='/Users/remaalnssiry/Desktop/SAND/Similarity_search/embeding', embedding_function=embedding).as_retriever()

    # Update the path to the correct JSON file location
    json_file_path = '/Users/remaalnssiry/Desktop/SAND/Similarity_search/result_dict.json'

    # Load the JSON mapping file
    with open(json_file_path, 'r') as f:
        file_mapping = json.load(f)

    def search_similarities(keyword):
        top_docs = retriever.get_relevant_documents(keyword)
        return top_docs[:2]

    st.markdown("""
        <style>
        body {
            direction: rtl;
            text-align: right;
        }
        .stTextInput label {
            float: right;
        }
        </style>
        """, unsafe_allow_html=True)

    st.title("Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©")

    user_query = st.text_area("ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ù‡ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ØªÙŠ ØªØ±ØºØ¨ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§:")

    if st.button("Ø¨Ø­Ø«"):
        if user_query:
            most_similar_docs = search_similarities(user_query)
            st.write("Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªØ´Ø§Ø¨Ù‡Ø§Ù‹:")

            for i, doc in enumerate(most_similar_docs):
                file_path = doc.metadata['file_path']
                file_name = os.path.basename(file_path)
                drive_id = file_mapping.get(file_path.replace("/Users/remaalnssiry/Desktop/SAND/dataset", ""))

                if drive_id:
                    drive_link = f"https://drive.google.com/file/d/{drive_id}/view"
                    st.write(f"**Ø§Ù„Ù‚Ø¶ÙŠÙ‡ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡ Ø±Ù‚Ù… {i+1}:**")
                    st.markdown(f" [Ù…Ù„Ù Ø§Ù„Ù‚Ø¶ÙŠÙ‡]({drive_link})", unsafe_allow_html=True)
                else:
                    st.write(f"**Ø§Ù„Ù‚Ø¶ÙŠÙ‡ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡ Ø±Ù‚Ù… {i+1}:**")
                    st.write(f"**Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù:** {file_path}")
                st.write(f"**ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù‚Ø¶ÙŠÙ‡:** {doc.page_content}")

            final_summary = ""
            for doc in most_similar_docs:
                chunks = text_splitter.split_text(doc.page_content)
                split_doc_chunks = [
                    Document(page_content=chunk, metadata={'file_path': doc.metadata['file_path'], 'chunk_index': i})
                    for i, chunk in enumerate(chunks)
                ]
                summary = map_reduce_chain.run(split_doc_chunks)
                final_summary += summary + "\n\n"

            st.write("**Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:**")
            st.write(final_summary)
        else:
            st.write("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø¯Ø®Ø§Ù„ Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠÙ‡.")

# Display the selected app
if app_selection == "Ø§Ù„Ø¨Ø§Ø­Ø« Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ":
    app1()
elif app_selection == "Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©":
    app2()
